{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4555d86-4eb4-4185-93d8-52f55da43df9",
   "metadata": {},
   "source": [
    "# Filter Training Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f767b5b-dd6e-48f8-aba4-259d72d8804a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Background\n",
    "\n",
    "It is not uncommon for existing training data to be collected over a different time period than that of the study period. Meaning that a dataset may not reflect the real ground cover due to temporal changes. \n",
    "\n",
    "The Food and Agriculture Organization (FAO) adopted a training data filtering method for any given reference year that is within a time span (e.g. 5 years) from an existing baseline, and tested the method in the production of land cover mapping for Lesotho. It is assumed that the majority of reference labels will remain valid from one year to the previous/next. Based on this assumption, the reference labels which have changed are the minority, and should be detectable through the use of outlier detection methods like K-Means clustering. More details on the method and how it works for Lesotho can be found in the published paper ([De Simone et al 2022](https://www.mdpi.com/2072-4292/14/14/3294))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ec80f-8f94-45f9-808c-712a572f8d89",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook will implement FAO's automatic filtering of a training dataset for a target year using points from a geojson or shapefile and a reference classification map of a previous year. The steps include:\n",
    "1. Load extracted training features\n",
    "2. Generate stratified random samples for each class on the reference land cover map using `random_sampling` and extract their features using `collect_training_data`\n",
    "3. Train K-Means models using the extracted features of the random samples\n",
    "4. Apply clustering on training features and remove minor clusters\n",
    "5. Export the filtered training features to disk for use in subsequent scripts\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba3177-6db9-4440-9c8b-d5437f41e7f4",
   "metadata": {},
   "source": [
    "### Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fccc7e0-768c-4479-a777-6ce9efbf4d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.3-CAPI-1.16.1). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import datacube\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from random_sampling import random_sampling # adapted from function by Chad Burton: https://gist.github.com/cbur24/04760d645aa123a3b1817b07786e7d9f\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efee6d6-c909-427c-bcb7-2943ae33b6bc",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "* `training_features_path`: The path to the file containing training features we extracted through the previous module `0_Extract_Training_Features.ipynb`.\n",
    "* `reference_map_path`: The path to the reference classification map, which will be used as a stratification layer to extract random samples for each class. In this example, we use the clipped and class-merged classification map produced from the notebook `0_Generate_Training_Points.ipynb`.**Note that the reference map pixel values should contain the class values existing in the training data.**\n",
    "* `class_attr`: This is the name of column in your shapefile/geojson file attribute table that contains the class labels. **The class labels must be integers**\n",
    "* `output_crs`: Output spatial reference system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62286a65-b4ae-4939-9c35-8b1675899e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_path = 'Results/Training_features_Kicukiro.txt'\n",
    "reference_map_path='Results/rwanda_landcover_2015_scheme_ii_clipped.tif'\n",
    "class_attr = 'LC_Class_I' # class label in integer format\n",
    "output_crs='epsg:32735' # WGS84/UTM Zone 35S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277e7e2-e195-43b0-9266-77a62813db76",
   "metadata": {},
   "source": [
    "## Load input data\n",
    "\n",
    "We now load the training features .txt file using `geopandas`. The pandas dataframe should contain columns `class_attr` identifying class labels and the bi-monthly geomedians of the nine spectral bands and NDVI that we extracted through previous module. It also contains the coordinates and geometry columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecf90a7-4fdf-40a9-90fc-edce613c6f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_Class_I</th>\n",
       "      <th>blue_0</th>\n",
       "      <th>blue_1</th>\n",
       "      <th>blue_2</th>\n",
       "      <th>blue_3</th>\n",
       "      <th>blue_4</th>\n",
       "      <th>blue_5</th>\n",
       "      <th>green_0</th>\n",
       "      <th>green_1</th>\n",
       "      <th>green_2</th>\n",
       "      <th>...</th>\n",
       "      <th>swir_2_2</th>\n",
       "      <th>swir_2_3</th>\n",
       "      <th>swir_2_4</th>\n",
       "      <th>swir_2_5</th>\n",
       "      <th>NDVI_0</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>NDVI_3</th>\n",
       "      <th>NDVI_4</th>\n",
       "      <th>NDVI_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1017.080444</td>\n",
       "      <td>966.000122</td>\n",
       "      <td>850.446106</td>\n",
       "      <td>494.834381</td>\n",
       "      <td>690.022949</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>1068.805298</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>985.529724</td>\n",
       "      <td>...</td>\n",
       "      <td>1333.680298</td>\n",
       "      <td>1362.772949</td>\n",
       "      <td>1729.421997</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>0.444562</td>\n",
       "      <td>0.501658</td>\n",
       "      <td>0.440377</td>\n",
       "      <td>0.379643</td>\n",
       "      <td>0.612270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>754.642151</td>\n",
       "      <td>522.500000</td>\n",
       "      <td>304.190826</td>\n",
       "      <td>456.111115</td>\n",
       "      <td>713.975525</td>\n",
       "      <td>316.253235</td>\n",
       "      <td>969.080383</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>544.479370</td>\n",
       "      <td>...</td>\n",
       "      <td>822.483643</td>\n",
       "      <td>987.639526</td>\n",
       "      <td>1664.428955</td>\n",
       "      <td>1004.478149</td>\n",
       "      <td>0.681496</td>\n",
       "      <td>0.698108</td>\n",
       "      <td>0.798872</td>\n",
       "      <td>0.683547</td>\n",
       "      <td>0.481418</td>\n",
       "      <td>0.730796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>486.022400</td>\n",
       "      <td>5124.000000</td>\n",
       "      <td>345.446167</td>\n",
       "      <td>448.232574</td>\n",
       "      <td>668.988892</td>\n",
       "      <td>1087.198486</td>\n",
       "      <td>688.981689</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>568.828186</td>\n",
       "      <td>...</td>\n",
       "      <td>1055.658081</td>\n",
       "      <td>1256.485474</td>\n",
       "      <td>1696.851074</td>\n",
       "      <td>1617.039917</td>\n",
       "      <td>0.751156</td>\n",
       "      <td>0.175494</td>\n",
       "      <td>0.800372</td>\n",
       "      <td>0.682261</td>\n",
       "      <td>0.502925</td>\n",
       "      <td>0.604687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>859.392029</td>\n",
       "      <td>1217.110718</td>\n",
       "      <td>709.319275</td>\n",
       "      <td>711.812683</td>\n",
       "      <td>848.868042</td>\n",
       "      <td>597.937622</td>\n",
       "      <td>1036.897461</td>\n",
       "      <td>1335.284912</td>\n",
       "      <td>1023.633240</td>\n",
       "      <td>...</td>\n",
       "      <td>1942.578979</td>\n",
       "      <td>2310.563232</td>\n",
       "      <td>2495.988281</td>\n",
       "      <td>2012.882324</td>\n",
       "      <td>0.424487</td>\n",
       "      <td>0.390258</td>\n",
       "      <td>0.441967</td>\n",
       "      <td>0.301718</td>\n",
       "      <td>0.285107</td>\n",
       "      <td>0.395637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>777.672852</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>692.216248</td>\n",
       "      <td>520.155273</td>\n",
       "      <td>597.163208</td>\n",
       "      <td>520.999817</td>\n",
       "      <td>951.130066</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>855.954285</td>\n",
       "      <td>...</td>\n",
       "      <td>1168.188843</td>\n",
       "      <td>1442.380737</td>\n",
       "      <td>1772.072998</td>\n",
       "      <td>1813.000122</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>0.445950</td>\n",
       "      <td>0.571246</td>\n",
       "      <td>0.448628</td>\n",
       "      <td>0.290127</td>\n",
       "      <td>0.447805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LC_Class_I       blue_0       blue_1      blue_2      blue_3      blue_4  \\\n",
       "0        10.0  1017.080444   966.000122  850.446106  494.834381  690.022949   \n",
       "1        10.0   754.642151   522.500000  304.190826  456.111115  713.975525   \n",
       "2        10.0   486.022400  5124.000000  345.446167  448.232574  668.988892   \n",
       "3        10.0   859.392029  1217.110718  709.319275  711.812683  848.868042   \n",
       "4        10.0   777.672852   700.000000  692.216248  520.155273  597.163208   \n",
       "\n",
       "        blue_5      green_0      green_1      green_2  ...     swir_2_2  \\\n",
       "0   338.000000  1068.805298  1150.000000   985.529724  ...  1333.680298   \n",
       "1   316.253235   969.080383   654.000000   544.479370  ...   822.483643   \n",
       "2  1087.198486   688.981689  5101.000000   568.828186  ...  1055.658081   \n",
       "3   597.937622  1036.897461  1335.284912  1023.633240  ...  1942.578979   \n",
       "4   520.999817   951.130066   893.000000   855.954285  ...  1168.188843   \n",
       "\n",
       "      swir_2_3     swir_2_4     swir_2_5    NDVI_0    NDVI_1    NDVI_2  \\\n",
       "0  1362.772949  1729.421997  1286.000000  0.480094  0.444562  0.501658   \n",
       "1   987.639526  1664.428955  1004.478149  0.681496  0.698108  0.798872   \n",
       "2  1256.485474  1696.851074  1617.039917  0.751156  0.175494  0.800372   \n",
       "3  2310.563232  2495.988281  2012.882324  0.424487  0.390258  0.441967   \n",
       "4  1442.380737  1772.072998  1813.000122  0.409946  0.445950  0.571246   \n",
       "\n",
       "     NDVI_3    NDVI_4    NDVI_5  \n",
       "0  0.440377  0.379643  0.612270  \n",
       "1  0.683547  0.481418  0.730796  \n",
       "2  0.682261  0.502925  0.604687  \n",
       "3  0.301718  0.285107  0.395637  \n",
       "4  0.448628  0.290127  0.447805  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features= pd.read_csv(training_features_path,sep=\" \")\n",
    "training_features.head() # Plot first five rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1983c2a7",
   "metadata": {},
   "source": [
    "Using the `class_attr` column we can get the class values, which we will use later to process by class. For this extracted training points, the class names corresponding to the class values are: `1: Forest, 5: Grassland, 7: Shrubland, 9: Perennial Cropland, 10: Annual Cropland, 11: Wetland, 12: Water Body, 13: Urban Settlement, 14: Bare Land`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5266d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "land cover classes:\n",
      " [10. 13. 11.  7.  9. 12.  1.  5. 14.]\n"
     ]
    }
   ],
   "source": [
    "lc_classes=training_features[class_attr].unique()\n",
    "print('land cover classes:\\n',lc_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42d4cf-ba19-45a8-b095-f42a070e4d92",
   "metadata": {},
   "source": [
    "The training data filtering method also requires a reference land cover map as a stratification layer to generate random training samples, which will be used to train the K-Means models, so we now load the class-merged clipped reference classification map that we previously produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0486c4df-5048-49ba-a572-90bd8d69d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference land cover classifcation raster:\n",
      " <xarray.DataArray (y: 469, x: 696)>\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)\n",
      "Coordinates:\n",
      "    band         int64 1\n",
      "  * x            (x) float64 30.05 30.05 30.05 30.05 ... 30.24 30.24 30.24 30.24\n",
      "  * y            (y) float64 -1.953 -1.953 -1.953 -1.954 ... -2.079 -2.079 -2.08\n",
      "    spatial_ref  int64 ...\n",
      "    variable     <U9 'band_data'\n"
     ]
    }
   ],
   "source": [
    "# load reference classification map\n",
    "reference_map = xr.open_dataset(reference_map_path,engine=\"rasterio\").astype(np.uint8)\n",
    "reference_map=reference_map.to_array().squeeze()\n",
    "print('Reference land cover classifcation raster:\\n',reference_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67922b67",
   "metadata": {},
   "source": [
    "## Generate random samples\n",
    "As part of the filtering method, we need some samples for each class to train a K-Means model, which will then be applied to cluster the training features. Here we generate some randomly distributed samples for each class using the reference classification map as stratification layer, in the same way we demonstrated to generate training samples in the notebook `0_Generate_Training_Points.ipynb`. Here we increase the total number of samples (around 1000) and minimum number of samples for the `random_sampling` function so that we get more samples to train the K-Means models. You can choose to export the generated random samples if you would like to check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430048b5-9d4c-4202-95e2-bd632759a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 10: sampling at 489 coordinates\n",
      "Class 13: sampling at 251 coordinates\n",
      "Class 11: sampling at 146 coordinates\n",
      "Class 7: sampling at 92 coordinates\n",
      "Class 9: sampling at 50 coordinates\n",
      "Class 12: sampling at 50 coordinates\n",
      "Class 1: sampling at 50 coordinates\n",
      "Class 5: sampling at 50 coordinates\n",
      "Class 14: sampling at 50 coordinates\n"
     ]
    }
   ],
   "source": [
    "class_attr='LC_Class_I'\n",
    "out_fname='Results/Random_samples_Kicukiro.geojson'\n",
    "gpd_random_samples=random_sampling(da=reference_map,n=1000,sampling='stratified_random',\n",
    "                                   min_sample_n=50,out_fname=out_fname,class_attr=class_attr,drop_value=0)\n",
    "gpd_random_samples[class_attr]=gpd_random_samples[class_attr].astype(int)\n",
    "gpd_random_samples=gpd_random_samples.set_crs(reference_map.rio.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07c8c5",
   "metadata": {},
   "source": [
    "## Extract features for the random samples\n",
    "With the random sample points available, we now need to extract `features` of the samples to train the K-Means models. Here we only use the NDVI composites to train the models. Through the previous notebook `1_Extract_Training_Features.ipynb` we demonstrated how to define query and extract features for a given set of points, so here we just reuse the functions and implement the same steps, but only keep NDVI bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eaaed-8e92-42ab-9b70-cbeaf331dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2021')\n",
    "measurements = ['red','nir_1']\n",
    "resolution = (-10,10)\n",
    "\n",
    "# detect the number of CPUs\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))\n",
    "\n",
    "query = {\n",
    "    'time': time,\n",
    "    'measurements': measurements,\n",
    "    'output_crs': output_crs,\n",
    "    'resolution': resolution\n",
    "}\n",
    "\n",
    "# define a function to feature layers\n",
    "def feature_layers(query): \n",
    "    # connect to the datacube so we can access DE Africa data\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    \n",
    "    # load Sentinel-2 analysis ready data\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "                  **query)\n",
    "    # calculate NDVI\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=True,\n",
    "                           satellite_mission='s2')\n",
    "    # calculate bi-monthly geomedian\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    list_stack_measures=[]\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            list_stack_measures.append(measure_single)\n",
    "    ds_stacked=xr.merge(list_stack_measures,compat='override')\n",
    "    return ds_stacked\n",
    "\n",
    "# collect training data\n",
    "column_names, model_input = collect_training_data(\n",
    "    gdf=gpd_random_samples,\n",
    "    dc_query=query,\n",
    "    ncpus=30,\n",
    "    field=class_attr,\n",
    "    zonal_stats=None,\n",
    "    feature_func=feature_layers,\n",
    "    return_coords=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93244f-60a5-4ddb-8e50-f5f1d551330a",
   "metadata": {},
   "source": [
    "Optionally you can export the extracted features for the random samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6d34b4-f54f-4641-8b1d-5574ca56c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to geopandas dataframe\n",
    "rand_samples_features=pd.DataFrame(data=model_input,columns=column_names)\n",
    "#set the name and location of the output file\n",
    "output_file = 'Results/Random_samples_features_Kicukiro.txt'\n",
    "#Export files to disk\n",
    "rand_samples_features.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50021c25-ec7c-477f-8833-31bf6a44927a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## K-Means clustering\n",
    "Now that we have the features of random samples and training points, we can use them to train and apply the K-Means models for each class. The K-Means model requires a pre-defined number of clusters, which is unknown for many cases. One way to identify the optimal number of clusters is using the Calinski-Harabasz Index. The index is the ratio of the sum of between-clusters dispersion and of within-cluster dispersion for all clusters, where the index is higher when clusters are dense and well separated. More information about can be checked [here](https://scikit-learn.org/stable/modules/clustering.html#calinski-harabasz-index). In this example we calculate the indices calculated from clustering with a varied number of clusters (e.g. 5 to 20) and retain the clustering with the highest index.  \n",
    "> Note: You can also use other indices to assess the clustering and choose optimal number of clusterings, see information on other indices [here](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation). Depending on the distribution of you features, different indices may lead to different optimal cluster numbers. Your number of clusters range will also likely result in different optimal clustering.\n",
    "\n",
    "Here we put the procedures in identifying the optimal clustering into a function where the inputs are the input features as numpy array, minimum and maximum numbers of clusters, and the outputs are the optimal number of clusters, trained K-Means model and corresponding clustering labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18f05f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters_KMeans(data,min_cluster=5,max_cluster=20):\n",
    "    highest_score=-999\n",
    "    n_cluster_optimal=min_cluster\n",
    "    kmeans_model_optimal=None # initialise optimal model parameters\n",
    "    labels_optimal=None\n",
    "    for n_cluster in range(min_cluster,max_cluster+1):\n",
    "        kmeans_model = KMeans(n_clusters=n_cluster, random_state=1).fit(data)\n",
    "        labels=kmeans_model.predict(data)\n",
    "        score=metrics.calinski_harabasz_score(data, labels)\n",
    "        print('Calinski-Harabasz score for ',n_cluster,' clusters is: ',score)\n",
    "        if (highest_score==-999)or(highest_score<score):\n",
    "            highest_score=score\n",
    "            n_cluster_optimal=n_cluster\n",
    "            kmeans_model_optimal=kmeans_model\n",
    "            labels_optimal=labels\n",
    "    if max_cluster>min_cluster:\n",
    "        print('Best number of clusters: %s'%(n_cluster_optimal))\n",
    "    return n_cluster_optimal,kmeans_model_optimal,labels_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513a9ab-5297-47b6-80e7-a6b3621cf71f",
   "metadata": {},
   "source": [
    "## Training data clustering - example for one class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0835f9cf",
   "metadata": {},
   "source": [
    "Using the above function, we now cluster the training features for the class Urban Settlement (13) as an example. We retain the NDVI features of random samples for the class, then apply the `find_clusters_KMeans` function to the random sample features to find optimal clustering. Here as an example we set the minimum and maximum numbers of clusters as 5 and 20, and you may want change the numbers based on your understanding on the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8102770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski-Harabasz score for  5  clusters is:  278.3310255485889\n",
      "Calinski-Harabasz score for  6  clusters is:  246.6693068298488\n",
      "Calinski-Harabasz score for  7  clusters is:  229.65857486237962\n",
      "Calinski-Harabasz score for  8  clusters is:  214.64620234185455\n",
      "Calinski-Harabasz score for  9  clusters is:  198.87171523013927\n",
      "Calinski-Harabasz score for  10  clusters is:  194.96772727923502\n",
      "Calinski-Harabasz score for  11  clusters is:  184.31245886014204\n",
      "Calinski-Harabasz score for  12  clusters is:  176.91498224751973\n",
      "Calinski-Harabasz score for  13  clusters is:  168.79396878666893\n",
      "Calinski-Harabasz score for  14  clusters is:  160.18927993464158\n",
      "Calinski-Harabasz score for  15  clusters is:  155.81178313294774\n",
      "Calinski-Harabasz score for  16  clusters is:  153.5808388812397\n",
      "Calinski-Harabasz score for  17  clusters is:  147.46701072704917\n",
      "Calinski-Harabasz score for  18  clusters is:  144.33689212689302\n",
      "Calinski-Harabasz score for  19  clusters is:  139.25199304735983\n",
      "Calinski-Harabasz score for  20  clusters is:  136.10685735918332\n",
      "Best number of clusters: 5\n"
     ]
    }
   ],
   "source": [
    "# get class label\n",
    "class_value=13\n",
    "# subset random sample features for this class\n",
    "rand_features_single_class=rand_samples_features[rand_samples_features[class_attr]==class_value].reset_index(drop=True)\n",
    "np_rand_features=rand_features_single_class.to_numpy()[:,1:]\n",
    "# find optimal clustering\n",
    "n_cluster_optimal,kmeans_model_optimal,labels_optimal=find_clusters_KMeans(np_rand_features,min_cluster=5,max_cluster=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a3ea5-6630-4ed0-a5c2-1aeb33854767",
   "metadata": {},
   "source": [
    "**Note**: If you are not happy with the number of cluster derived from the Calinski-Harabasz score, simply set both the `min_cluster` and `max_cluster` the same number you want and run the function, For example if you want 10 clusters then use the function as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64621d52-108c-4e18-b907-04e54409f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski-Harabasz score for  10  clusters is:  194.96772727923502\n"
     ]
    }
   ],
   "source": [
    "n_cluster_optimal,kmeans_model_optimal,labels_optimal=find_clusters_KMeans(np_rand_features,min_cluster=10,max_cluster=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133aa86",
   "metadata": {},
   "source": [
    "After identifying the optimal clustering, we can apply the optimal K-Means model to NDVIs of our training points. Here we assign the clustering labels to a new column `cluster`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe8e1ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training pints for the class:  126\n"
     ]
    }
   ],
   "source": [
    "# subset original training points for this class\n",
    "td_single_class=training_features[training_features[class_attr]==class_value].reset_index(drop=True)\n",
    "print('Number of training pints for the class: ',len(td_single_class))\n",
    "np_td_single_class=td_single_class.to_numpy()[:,-6:]\n",
    "# predict clustering labels\n",
    "labels_kmeans = kmeans_model_optimal.predict(np_td_single_class)\n",
    "# append clustering results to pixel coordinates\n",
    "td_single_class['cluster']=labels_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ac4cf-c9a2-4411-88ee-8a4d032f2159",
   "metadata": {},
   "source": [
    "To visualise the distribution of a two-month composite of NDVI values for all clusters (e.g. March-April NDVI composites):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6855de8-8c57-4ed6-a422-8e343f5475b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(-0.5, 1, 100)\n",
    "for cluster in range(n_cluster_optimal):\n",
    "    td_cluster=td_single_class[td_single_class['cluster']==cluster]\n",
    "    td_cluster=td_cluster['NDVI_2'].to_numpy()\n",
    "    plt.hist(td_cluster,bins, alpha=0.5, label='cluster'+str(cluster),rwidth=0.8);\n",
    "    plt.legend()\n",
    "    plt.xlabel('NDVI')\n",
    "    plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12b5a7-3e88-48bf-b2d3-f4b56d7a2f45",
   "metadata": {},
   "source": [
    "We now filter the training features/points based on the cluster size. Here we assume cluster size lower than 10% of the overall sample szie are likely to be misclassified or changed samples.    \n",
    ">Note: Depending on your own training data the K-Means method may not work well, so it is recommanded that you have more understanding on your training points and test on how it works, e.g. check if it successfully filtered out the points you believe were misclassified while keeping good training samples. You should also try to adjust the cluster size threshold if it doesn't effectively remove false samples.\n",
    "\n",
    "There are also other options for removal of outliers which can be tested on, e.g. check [here](https://scikit-learn.org/stable/modules/outlier_detection.html) for using scikit-learn for outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cc49dd0-2396-484b-808d-657af599a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data after filtering:  94\n"
     ]
    }
   ],
   "source": [
    "frequency_threshold=0.1 # threshold of cluter frequency\n",
    "cluster_frequency=td_single_class['cluster'].map(td_single_class['cluster'].value_counts(normalize=True)) # calculate cluster frequencies for the training samples\n",
    "td_single_class['cluster_frequency']=cluster_frequency # append as a column\n",
    "td_single_class_filtered=td_single_class[td_single_class['cluster_frequency']>=frequency_threshold] # filter by cluster frequency\n",
    "print('Number of training data after filtering: ',len(td_single_class_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e22329-c20c-44b6-9b3b-2f931ac36f79",
   "metadata": {},
   "source": [
    "You can compare the number of training points before and after the filtering and check whether and how many pixels were filtered out. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f139e22-8ba8-40e8-af8c-bc75d0654883",
   "metadata": {},
   "source": [
    "**Note**: If you opt to fine-tune the number of clusters for another class, simply change the `class_value` to another class value and re-run the steps within this `Training data clustering - example for one class` section. After you find the optimal numbers of clusters, change below dictionary `None` to the optimal number for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7490c84-48ab-43ea-a202-fd334a4da896",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_clusters={1:None, 5: None, 7: None,  9: None, 10: None, 11: None,  12: None,  13: None,  14: None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d34d72",
   "metadata": {},
   "source": [
    "## Training data clustering - all classes\n",
    "To implement above clustering and filtering training features for all class, let's put the steps together and iterate through all classes. Here we append filtered features for all classes into a single dataframe `training_features_filtered`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fd905a2-2137-4fb0-8c4b-3098c8c96b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class  10.0\n",
      "Calinski-Harabasz score for  5  clusters is:  276.30448211511487\n",
      "Calinski-Harabasz score for  6  clusters is:  241.9619570879561\n",
      "Calinski-Harabasz score for  7  clusters is:  219.66365012351486\n",
      "Calinski-Harabasz score for  8  clusters is:  201.99347103476862\n",
      "Calinski-Harabasz score for  9  clusters is:  187.0690147726517\n",
      "Calinski-Harabasz score for  10  clusters is:  174.84532236108677\n",
      "Calinski-Harabasz score for  11  clusters is:  165.59287614279228\n",
      "Calinski-Harabasz score for  12  clusters is:  157.36726797314324\n",
      "Calinski-Harabasz score for  13  clusters is:  150.79076134796833\n",
      "Calinski-Harabasz score for  14  clusters is:  143.92454702016445\n",
      "Calinski-Harabasz score for  15  clusters is:  139.30576745836444\n",
      "Calinski-Harabasz score for  16  clusters is:  135.20113167010194\n",
      "Calinski-Harabasz score for  17  clusters is:  129.25065444720386\n",
      "Calinski-Harabasz score for  18  clusters is:  124.47831350865259\n",
      "Calinski-Harabasz score for  19  clusters is:  120.32910474357142\n",
      "Calinski-Harabasz score for  20  clusters is:  118.75638799868976\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  245\n",
      "Number of training data after filtering:  245\n",
      "Processing class  13.0\n",
      "Calinski-Harabasz score for  5  clusters is:  278.3310255485889\n",
      "Calinski-Harabasz score for  6  clusters is:  246.6693068298488\n",
      "Calinski-Harabasz score for  7  clusters is:  229.65857486237962\n",
      "Calinski-Harabasz score for  8  clusters is:  214.64620234185455\n",
      "Calinski-Harabasz score for  9  clusters is:  198.87171523013927\n",
      "Calinski-Harabasz score for  10  clusters is:  194.96772727923502\n",
      "Calinski-Harabasz score for  11  clusters is:  184.31245886014204\n",
      "Calinski-Harabasz score for  12  clusters is:  176.91498224751973\n",
      "Calinski-Harabasz score for  13  clusters is:  168.79396878666893\n",
      "Calinski-Harabasz score for  14  clusters is:  160.18927993464158\n",
      "Calinski-Harabasz score for  15  clusters is:  155.81178313294774\n",
      "Calinski-Harabasz score for  16  clusters is:  153.5808388812397\n",
      "Calinski-Harabasz score for  17  clusters is:  147.46701072704917\n",
      "Calinski-Harabasz score for  18  clusters is:  144.33689212689302\n",
      "Calinski-Harabasz score for  19  clusters is:  139.25199304735983\n",
      "Calinski-Harabasz score for  20  clusters is:  136.10685735918332\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  126\n",
      "Number of training data after filtering:  126\n",
      "Processing class  11.0\n",
      "Calinski-Harabasz score for  5  clusters is:  52.74302335012713\n",
      "Calinski-Harabasz score for  6  clusters is:  47.388580022166366\n",
      "Calinski-Harabasz score for  7  clusters is:  42.84900884579891\n",
      "Calinski-Harabasz score for  8  clusters is:  41.438145276912046\n",
      "Calinski-Harabasz score for  9  clusters is:  38.96184779594936\n",
      "Calinski-Harabasz score for  10  clusters is:  37.605908093830685\n",
      "Calinski-Harabasz score for  11  clusters is:  36.43917619124269\n",
      "Calinski-Harabasz score for  12  clusters is:  36.02051366465202\n",
      "Calinski-Harabasz score for  13  clusters is:  34.692048071556556\n",
      "Calinski-Harabasz score for  14  clusters is:  33.31453713281372\n",
      "Calinski-Harabasz score for  15  clusters is:  35.15345489217292\n",
      "Calinski-Harabasz score for  16  clusters is:  34.182109354797845\n",
      "Calinski-Harabasz score for  17  clusters is:  32.84387905111512\n",
      "Calinski-Harabasz score for  18  clusters is:  33.157442501845594\n",
      "Calinski-Harabasz score for  19  clusters is:  32.6720265844677\n",
      "Calinski-Harabasz score for  20  clusters is:  31.98295090018111\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  73\n",
      "Number of training data after filtering:  73\n",
      "Processing class  7.0\n",
      "Calinski-Harabasz score for  5  clusters is:  55.99688879127466\n",
      "Calinski-Harabasz score for  6  clusters is:  51.428270123215086\n",
      "Calinski-Harabasz score for  7  clusters is:  48.7186575498774\n",
      "Calinski-Harabasz score for  8  clusters is:  45.41264721674636\n",
      "Calinski-Harabasz score for  9  clusters is:  41.251398691851485\n",
      "Calinski-Harabasz score for  10  clusters is:  41.90577513622804\n",
      "Calinski-Harabasz score for  11  clusters is:  40.71152554794014\n",
      "Calinski-Harabasz score for  12  clusters is:  39.70193770099515\n",
      "Calinski-Harabasz score for  13  clusters is:  40.14124432772564\n",
      "Calinski-Harabasz score for  14  clusters is:  38.476912896036104\n",
      "Calinski-Harabasz score for  15  clusters is:  39.14675686089902\n",
      "Calinski-Harabasz score for  16  clusters is:  37.8909396839081\n",
      "Calinski-Harabasz score for  17  clusters is:  39.02282829064332\n",
      "Calinski-Harabasz score for  18  clusters is:  36.997610944463794\n",
      "Calinski-Harabasz score for  19  clusters is:  36.338201591642985\n",
      "Calinski-Harabasz score for  20  clusters is:  36.783403490090116\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  46\n",
      "Number of training data after filtering:  42\n",
      "Processing class  9.0\n",
      "Calinski-Harabasz score for  5  clusters is:  25.716761776508815\n",
      "Calinski-Harabasz score for  6  clusters is:  22.996893106669884\n",
      "Calinski-Harabasz score for  7  clusters is:  21.283827255936668\n",
      "Calinski-Harabasz score for  8  clusters is:  20.584662552047725\n",
      "Calinski-Harabasz score for  9  clusters is:  18.483187737355177\n",
      "Calinski-Harabasz score for  10  clusters is:  17.965657844913288\n",
      "Calinski-Harabasz score for  11  clusters is:  17.789150511511366\n",
      "Calinski-Harabasz score for  12  clusters is:  17.67048645215216\n",
      "Calinski-Harabasz score for  13  clusters is:  17.36826322571985\n",
      "Calinski-Harabasz score for  14  clusters is:  17.131104500572075\n",
      "Calinski-Harabasz score for  15  clusters is:  16.835956472937163\n",
      "Calinski-Harabasz score for  16  clusters is:  16.663515575001597\n",
      "Calinski-Harabasz score for  17  clusters is:  16.56604959275107\n",
      "Calinski-Harabasz score for  18  clusters is:  16.05590700923053\n",
      "Calinski-Harabasz score for  19  clusters is:  16.80938199144785\n",
      "Calinski-Harabasz score for  20  clusters is:  16.13561598586214\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  20\n",
      "Number of training data after filtering:  19\n",
      "Processing class  12.0\n",
      "Calinski-Harabasz score for  5  clusters is:  99.33610359971897\n",
      "Calinski-Harabasz score for  6  clusters is:  88.96680829818952\n",
      "Calinski-Harabasz score for  7  clusters is:  83.29361068956554\n",
      "Calinski-Harabasz score for  8  clusters is:  77.46077580211549\n",
      "Calinski-Harabasz score for  9  clusters is:  74.21869113141447\n",
      "Calinski-Harabasz score for  10  clusters is:  70.9914934227254\n",
      "Calinski-Harabasz score for  11  clusters is:  70.75021659205314\n",
      "Calinski-Harabasz score for  12  clusters is:  68.00003013775431\n",
      "Calinski-Harabasz score for  13  clusters is:  70.44221388423215\n",
      "Calinski-Harabasz score for  14  clusters is:  65.75233897809788\n",
      "Calinski-Harabasz score for  15  clusters is:  70.69379611903648\n",
      "Calinski-Harabasz score for  16  clusters is:  72.27964715752\n",
      "Calinski-Harabasz score for  17  clusters is:  70.40472400222573\n",
      "Calinski-Harabasz score for  18  clusters is:  69.73327167390362\n",
      "Calinski-Harabasz score for  19  clusters is:  70.21123914483846\n",
      "Calinski-Harabasz score for  20  clusters is:  69.4970810081947\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  20\n",
      "Number of training data after filtering:  19\n",
      "Processing class  1.0\n",
      "Calinski-Harabasz score for  5  clusters is:  51.68830842124932\n",
      "Calinski-Harabasz score for  6  clusters is:  46.728330225992316\n",
      "Calinski-Harabasz score for  7  clusters is:  43.439559778509086\n",
      "Calinski-Harabasz score for  8  clusters is:  42.20492930948123\n",
      "Calinski-Harabasz score for  9  clusters is:  39.28157979948487\n",
      "Calinski-Harabasz score for  10  clusters is:  37.34108105131072\n",
      "Calinski-Harabasz score for  11  clusters is:  37.30185693262288\n",
      "Calinski-Harabasz score for  12  clusters is:  38.28236182464218\n",
      "Calinski-Harabasz score for  13  clusters is:  35.584846787957844\n",
      "Calinski-Harabasz score for  14  clusters is:  34.4751765435604\n",
      "Calinski-Harabasz score for  15  clusters is:  34.21001860637948\n",
      "Calinski-Harabasz score for  16  clusters is:  34.265155467271754\n",
      "Calinski-Harabasz score for  17  clusters is:  33.193718174469694\n",
      "Calinski-Harabasz score for  18  clusters is:  33.94691772302392\n",
      "Calinski-Harabasz score for  19  clusters is:  33.93932690790943\n",
      "Calinski-Harabasz score for  20  clusters is:  33.117652187870135\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  20\n",
      "Number of training data after filtering:  20\n",
      "Processing class  5.0\n",
      "Calinski-Harabasz score for  5  clusters is:  50.62564170082489\n",
      "Calinski-Harabasz score for  6  clusters is:  47.79504096084726\n",
      "Calinski-Harabasz score for  7  clusters is:  46.823215339212595\n",
      "Calinski-Harabasz score for  8  clusters is:  44.145508405763415\n",
      "Calinski-Harabasz score for  9  clusters is:  42.77174915044249\n",
      "Calinski-Harabasz score for  10  clusters is:  40.718141772684554\n",
      "Calinski-Harabasz score for  11  clusters is:  38.67624271063278\n",
      "Calinski-Harabasz score for  12  clusters is:  39.62887024563943\n",
      "Calinski-Harabasz score for  13  clusters is:  38.709639135950844\n",
      "Calinski-Harabasz score for  14  clusters is:  38.03399209057758\n",
      "Calinski-Harabasz score for  15  clusters is:  37.017628534682274\n",
      "Calinski-Harabasz score for  16  clusters is:  38.49710383505709\n",
      "Calinski-Harabasz score for  17  clusters is:  38.4140043798445\n",
      "Calinski-Harabasz score for  18  clusters is:  38.07058853891347\n",
      "Calinski-Harabasz score for  19  clusters is:  38.110050267978515\n",
      "Calinski-Harabasz score for  20  clusters is:  39.89523261853399\n",
      "Best number of clusters: 5\n",
      "Number of training pints for the class:  20\n",
      "Number of training data after filtering:  19\n",
      "Processing class  14.0\n",
      "Calinski-Harabasz score for  5  clusters is:  131.79980662135335\n",
      "Calinski-Harabasz score for  6  clusters is:  141.61359127253868\n",
      "Calinski-Harabasz score for  7  clusters is:  136.27431604508027\n",
      "Calinski-Harabasz score for  8  clusters is:  132.5769332853955\n",
      "Calinski-Harabasz score for  9  clusters is:  129.19007834437835\n",
      "Calinski-Harabasz score for  10  clusters is:  125.11306863773584\n",
      "Calinski-Harabasz score for  11  clusters is:  128.99451309768716\n",
      "Calinski-Harabasz score for  12  clusters is:  131.31914828686644\n",
      "Calinski-Harabasz score for  13  clusters is:  128.34176370109392\n",
      "Calinski-Harabasz score for  14  clusters is:  133.82234668139108\n",
      "Calinski-Harabasz score for  15  clusters is:  127.29928452183323\n",
      "Calinski-Harabasz score for  16  clusters is:  136.47746416842227\n",
      "Calinski-Harabasz score for  17  clusters is:  133.3977882550244\n",
      "Calinski-Harabasz score for  18  clusters is:  132.7268550308296\n",
      "Calinski-Harabasz score for  19  clusters is:  136.6121480778877\n",
      "Calinski-Harabasz score for  20  clusters is:  144.56414110131396\n",
      "Best number of clusters: 20\n",
      "Number of training pints for the class:  20\n",
      "Number of training data after filtering:  12\n"
     ]
    }
   ],
   "source": [
    "training_features_filtered=None # filtered training data for all classes\n",
    "frequency_threshold=0.1 # threshold of cluter frequency\n",
    "for class_value in lc_classes: # filtering training data for each class\n",
    "    #i=1 # test for first class\n",
    "    print('Processing class ',class_value)\n",
    "    rand_features_single_class=rand_samples_features[rand_samples_features[class_attr]==class_value].reset_index(drop=True)\n",
    "    np_rand_features=rand_features_single_class.to_numpy()[:,1:]\n",
    "    if optimal_clusters[class_value] is None:\n",
    "        n_cluster_optimal,kmeans_model_optimal,labels_optimal=find_clusters_KMeans(np_rand_features,min_cluster=5,max_cluster=20)\n",
    "    else:\n",
    "        n_cluster_optimal,kmeans_model_optimal,labels_optimal=find_clusters_KMeans(np_rand_features,min_cluster=optimal_clusters[class_value],max_cluster=optimal_clusters[class_value])\n",
    "\n",
    "        # subset original training points for this class\n",
    "    td_single_class=training_features[training_features[class_attr]==class_value].reset_index(drop=True)\n",
    "    print('Number of training pints for the class: ',len(td_single_class))\n",
    "    np_td_single_class=td_single_class.to_numpy()[:,-6:]\n",
    "    # predict clustering labels\n",
    "    labels_kmeans = kmeans_model_optimal.predict(np_td_single_class)\n",
    "    # append clustering results to pixel coordinates\n",
    "    td_single_class['cluster']=labels_kmeans\n",
    "\n",
    "    cluster_frequency=td_single_class['cluster'].map(td_single_class['cluster'].value_counts(normalize=True)) # calculate cluster frequencies for the training samples\n",
    "    td_single_class['cluster_frequency']=cluster_frequency # append as a column\n",
    "    td_single_class_filtered=td_single_class[td_single_class['cluster_frequency']>=frequency_threshold] # filter by cluster frequency\n",
    "    print('Number of training data after filtering: ',len(td_single_class_filtered))\n",
    "    \n",
    "    # append the filtered training points of this class to final filtered training data\n",
    "    if training_features_filtered is None:\n",
    "        training_features_filtered=td_single_class_filtered\n",
    "    else:\n",
    "        training_features_filtered=pd.concat([training_features_filtered, td_single_class_filtered])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffedd3d-6817-4c3a-aca6-d5b5d98f85ad",
   "metadata": {},
   "source": [
    "## Export filtered training features\n",
    "Once we've filtered the training signatures, we can write the filtered data to disk, which will allow us to import the data in the next step(s) of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97829f-3578-4ce3-95e6-ba2be2b99820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export the filtered training data as geojson file\n",
    "# output_file = \"Results/Rwanda_training_features_2021_filtered.geojson\"\n",
    "# training_features_filtered.to_file(output_file, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ed675c5-4dc6-4f71-850f-55e0c685334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"Results/Training_features_Kicukiro_filtered.txt\"\n",
    "training_features_filtered.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5083af-a9c3-4373-b972-729d51ce21b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
