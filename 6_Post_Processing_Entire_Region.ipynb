{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13adbce-103d-40c4-88bd-bb94d3d848f1",
   "metadata": {},
   "source": [
    "# Post-process for Entire District"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fb223-9745-4711-9a51-a1384dbcc63e",
   "metadata": {},
   "source": [
    "## Description\n",
    "Once you are happy with the post-processed results through previous notebook, you can then implement the same post-processing steps for the entire district of interest. To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f4e28-0a6a-4d30-973d-e2f1b20acf2a",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4986f5-2e04-4e64-8ff0-25119e9468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import datacube\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.plotting import rgb\n",
    "from skimage.morphology import binary_dilation,disk\n",
    "from skimage.filters.rank import modal\n",
    "from skimage.segmentation import expand_labels\n",
    "from odc.algo import xr_reproject\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap,BoundaryNorm\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74765-a79f-4bb2-baa5-240c6cacc41e",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "* `prediction_map_path`: File path and name of the classification map for the entire district.\n",
    "* `dict_map`: A dictionary map of class names corresponding to pixel values.\n",
    "* `output_crs`: Coordinate reference system for output raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269eb27c-1692-4461-830b-185ffaa8008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_map_path='Results/Land_cover_prediction.tif'\n",
    "dict_map={'Forest':1,'Grassland':5,'Shrubland':7,'Perennial Cropland':9,'Annual Cropland':10,\n",
    "          'Wetland':11,'Water Body':12,'Urban Settlement':13,'Bare Land':14} # a dictionary of pixel value for each class\n",
    "output_crs='epsg:32735' # WGS84/UTM Zone 35S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9884a-c98d-4d0a-8dca-d1cadb986c36",
   "metadata": {},
   "source": [
    "## External Layers\n",
    "A few external layers for Rwanda were sourced and prepared in the 'Data/' folder, which are helpful to add information on specific classes. The external layers include:  \n",
    "* `river_network_shp`: OSM river network shapefile. The OSM layers were sourced from the [Humanitarian OpenStreetMap Team (HOT)](https://data.humdata.org/organization/hot) website.\n",
    "* `road_network_shp`: OSM road network shapefile.\n",
    "* `google_building_raster`: A rasterised layer of [Google Open Building](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_Research_open-buildings_v2_polygons) polygons, which consist of outlines of buildings derived from high-resolution 50 cm satellite imagery. As there are many polygons in the original vector layer, we rasterised the layer to 10 m resolution to reduce disk storage and memory required for processing.  \n",
    "* `wsf2019_raster`: 2019 [World Settlement Footprint (WSF)](https://gee-community-catalog.org/projects/wsf/) layer, a 10m resolution binary mask outlining the extent of human settlements globally derived by means of 2019 multitemporal Sentinel-1 and Sentinel-2 imagery.  \n",
    "* `hand_raster`: Hydrologically adjusted elevations, i.e. Height Above the Nearest Drainage (hand) derived from the [MERIT Hydro dataset](https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1#description).\n",
    "* `parks_json`: Boundaries of [national parks or reserve](https://geodata.rw/server/rest/services/basemap/National_Parks/FeatureServer/0) declared or registered by the government in geojson format.\n",
    "* `wetlands_json`: Boundaries of [declaired swamps borders](https://geodata.rw/server/rest/services/basemap/Wetland/FeatureServer/0) in geojson format.\n",
    "\n",
    "> Note: In this notebook we have made the data prepared for you to run through the demonstration. If you would like to apply it to your own project, you may need to spend some time sourcing the datasets and do some pre-processing if needed, e.g. clipping to your study area, filtering, rasterisation or vectorisation. Alternatively you can revise this notebook depending on the file format of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12234399-7fda-4885-bce2-478634840400",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network_shp='Data/hotosm_rwa_waterways_lines_filtered.shp' # OSM river network data\n",
    "road_network_shp='Data/hotosm_rwa_roads_lines_filtered.shp' # OSM road network data\n",
    "google_building_raster='Data/GoogleBuildingLayer_Rwanda_reprojected_rasterised.tif' # rasterised google bulding layer\n",
    "wsf2019_raster='Data/WSF2019_v1_Rwanda_clipped.tif' # 2019 World Settlement Footprint layer\n",
    "hand_raster='Data/hand_Rwanda.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "parks_json='Data/National Parks.geojson' # National parks layer\n",
    "wetlands_json='Data/Wetland.geojson' # wetlands layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2b93c-e69f-46b1-9df4-715dc11f0b04",
   "metadata": {},
   "source": [
    "## Load land cover map and external layers\n",
    "First let's load the land cover map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c855d-7100-4d48-8a8b-5219ddcf0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import land cover map of 2021 and reproject\n",
    "lc_map=rioxarray.open_rasterio(prediction_map_path).astype(np.uint8).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64fc6c-856d-4185-926d-76d44872243c",
   "metadata": {},
   "source": [
    "We then load other layers. The OSM road network layer contains multi-lines with various surface attributes. We'll select some major road types and buffer them by 10 metres. Similarly we load and select major waterways from the OSM river network layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616870ab-3aad-439d-bbae-9833ab9e3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_network=gpd.read_file(road_network_shp).to_crs(output_crs) \n",
    "road_network=road_network.loc[road_network['surface'].isin(['asphalt', 'paved', 'compacted', 'cobblestone', \n",
    "                                                             'concrete', 'metal', 'paving_stones', \n",
    "                                                             'paving_stones:30'])] # select road network by attributes\n",
    "road_network.geometry=road_network.geometry.buffer(10) # buffer the road network by 10m\n",
    "\n",
    "river_network=gpd.read_file(river_network_shp).to_crs(output_crs) # import OSM river network data and reproject\n",
    "river_network=river_network.loc[river_network['waterway'].isin(['canal','river'])] # select river network by attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8469a6-6e9b-44f1-a975-622f258eb170",
   "metadata": {},
   "source": [
    "We now load the Google buildings, WSF 2019 and 'hand' rasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c28d0d-b5a2-4a83-9567-6e2e17a6b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings=xr.open_dataset(google_building_raster,engine=\"rasterio\").squeeze() # import google bulding layer\n",
    "hand=xr.open_dataset(hand_raster,engine=\"rasterio\").squeeze() # import hand layer\n",
    "wsf2019=xr.open_dataset(wsf2019_raster,engine=\"rasterio\").squeeze().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0f0ae",
   "metadata": {},
   "source": [
    "Finally let's load the national parks and wetlands layers, and select the national parks with no agricultural activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d98c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks=gpd.read_file(parks_json).to_crs(output_crs)\n",
    "parks=parks.loc[parks['type'].isin(['National Park','Volcanoes National Park'])]\n",
    "wetlands=gpd.read_file(wetlands_json).to_crs(output_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6beb26-1701-4135-802f-53d65cd7cab8",
   "metadata": {},
   "source": [
    "## Morphological filtering and apply all rules\n",
    "We now apply the filtering and all the rules as implemented in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "np_lc_map=lc_map.squeeze().to_numpy()\n",
    "\n",
    "# --------------------mode filtering for a smoother classification map----------------------#\n",
    "np_lc_map_postproc=modal(np_lc_map,footprint=disk(1),mask=np_lc_map!=0)\n",
    "\n",
    "# get geobox\n",
    "ds_geobox=lc_map.geobox\n",
    "\n",
    "# merging two cropland classes\n",
    "np_lc_map_postproc[np_lc_map_postproc==dict_map['Perennial Cropland']]=dict_map['Annual Cropland']\n",
    "\n",
    "#--------------------reassign Cropland within national parks as Shrubland------------------------#\n",
    "# rasterise national parks layer\n",
    "parks_mask=xr_rasterize(gdf=parks,da=lc_map.squeeze(),transform=ds_geobox.transform,crs=output_crs)\n",
    "np_parks_mask=parks_mask.squeeze().to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[(np_lc_map_postproc==dict_map['Annual Cropland'])&(np_parks_mask==1)]=dict_map['Shrubland']\n",
    "\n",
    "#--------------------reassign Urban Settlement within national parks as surrounding classes------------------------#\n",
    "# make a copy of land cover array\n",
    "lc_copy=np_lc_map_postproc.copy()\n",
    "# assign the regions as background (0)\n",
    "lc_copy[(np_lc_map_postproc==dict_map['Urban Settlement'])&(np_parks_mask==1)]=0\n",
    "# expand surrounding classes of background pixels\n",
    "lc_copy_closed=expand_labels(lc_copy,distance=10000)\n",
    "# identify filled/changed areas\n",
    "mask=(lc_copy!=lc_copy_closed)\n",
    "# copy the filled/changed pixels\n",
    "np_lc_map_postproc[mask]=lc_copy_closed[mask]\n",
    "\n",
    "#--------------------reassign Wetland outside wetland polygons as Shrubland------------------------#\n",
    "wetlands_mask=xr_rasterize(gdf=wetlands,da=lc_map.squeeze(),transform=ds_geobox.transform,crs=output_crs)\n",
    "np_wetlands_mask=wetlands_mask.squeeze().to_numpy()\n",
    "np_lc_map_postproc[(np_lc_map_postproc==dict_map['Wetland'])&(np_wetlands_mask!=1)]=dict_map['Shrubland']\n",
    "\n",
    "#------reassign Bare Land and Urban Settlement within DE Africa crop mask as Cropland; Cropland outside the mask as Shrubland------#\n",
    "# load DE Africa crop mask 2019\n",
    "dc = datacube.Datacube(app='cropland_extent')\n",
    "# extract bounding box\n",
    "x_min,y_min,x_max,y_max=ds_geobox.extent.boundingbox\n",
    "query = {\n",
    "    'time': ('2019'),\n",
    "    'x': (x_min,x_max),\n",
    "    'y': (y_min,y_max),\n",
    "    'resolution':(-10, 10),\n",
    "    'crs':output_crs,\n",
    "    'output_crs': output_crs,\n",
    "}\n",
    "# now load the crop-mask using the query\n",
    "cm = dc.load(product='crop_mask',**query).squeeze()\n",
    "np_crop_mask=cm['mask'].to_numpy()\n",
    "# apply the rules\n",
    "np_lc_map_postproc[((np_lc_map_postproc==dict_map['Bare Land'])|(np_lc_map_postproc==dict_map['Urban Settlement']))\n",
    "&(np_crop_mask==1)]=dict_map['Annual Cropland']\n",
    "np_lc_map_postproc[(np_lc_map_postproc==dict_map['Annual Cropland'])&(np_crop_mask!=1)]=dict_map['Shrubland']\n",
    "\n",
    "#--------------------assign pixels within OSM river network as Water Body------------------------#\n",
    "# reproject hand layer\n",
    "hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_hand=hand.to_array().squeeze().to_numpy()\n",
    "# rasterise river network layer\n",
    "river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                da=lc_map.squeeze(),\n",
    "                                transform=ds_geobox.transform,\n",
    "                                crs=output_crs)\n",
    "# convert to numpy array\n",
    "np_river_network_mask=river_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[np_river_network_mask==1]=dict_map['Water Body']\n",
    "\n",
    "#--------------------make sure water body only present at bottom of watershed or within OSM river network-----------#\n",
    "# make a copy of land cover array\n",
    "lc_copy=np_lc_map_postproc.copy()\n",
    "# assign the regions as background (0)\n",
    "lc_copy[(np_lc_map_postproc==dict_map['Water Body'])&(np_hand>45)&(np_river_network_mask!=1)]=0\n",
    "# expand surrounding classes of background pixels\n",
    "lc_copy_closed=expand_labels(lc_copy,distance=10000)\n",
    "# identify filled/changed areas\n",
    "mask=(lc_copy!=lc_copy_closed)\n",
    "# copy the filled/changed pixels\n",
    "np_lc_map_postproc[mask]=lc_copy_closed[mask]\n",
    "\n",
    "#--------------------assign pixels overlapping google building, WSF 2019 and OSM road network as Urban Settlement---------#\n",
    "# reproject google buildings raster\n",
    "google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "# reproject WSF 2019 layer\n",
    "wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "# convert to numpy array\n",
    "np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "# rasterise road network layer\n",
    "road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                            da=lc_map.squeeze(),\n",
    "                            transform=ds_geobox.transform,\n",
    "                            crs=output_crs)\n",
    "# convert to numpy\n",
    "np_road_network_mask=road_network_mask.to_numpy()\n",
    "# apply rule\n",
    "np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==255)|(np_road_network_mask==1)]=dict_map['Urban Settlement']\n",
    "\n",
    "#------------------------------reconstruct processed result as Xarray---------------------------------#\n",
    "# \n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                         coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "# set spatial reference\n",
    "lc_map_postproc.rio.write_crs(output_crs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9e53c-0b31-4fdc-b613-23da0c566a78",
   "metadata": {},
   "source": [
    "To compare the post-processed result with initial prediction without post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab9e08-ec61-43e2-a05e-33a8865be61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "dict_map_merged={'Forest':1,'Grassland':5,'Shrubland':7,'Cropland':10,\n",
    "          'Wetland':11,'Water Body':12,'Urban Settlement':13,'Bare Land':14}\n",
    "\n",
    "colours = {1:'green', 5:'gold', 7:'chocolate',9:'violet',10:'pink',11:'cyan',12:'blue',13:'gray',14:'seashell'}\n",
    "colours_merged={1:'green', 5:'gold', 7:'chocolate',10:'pink',11:'cyan',12:'blue',13:'gray',14:'seashell'}\n",
    "\n",
    "patches_list=[Patch(facecolor=colour) for colour in colours.values()]\n",
    "patches_list_merged=[Patch(facecolor=colour) for colour in colours_merged.values()]\n",
    "\n",
    "# set color legends and color maps parameters\n",
    "prediction_values=np.unique(lc_map)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "\n",
    "prediction_values_merged=np.unique(lc_map_postproc)\n",
    "cmap_merged=ListedColormap([colours_merged[k] for k in prediction_values_merged])\n",
    "norm_merged = BoundaryNorm(list(prediction_values_merged)+[np.max(prediction_values_merged)+1], cmap_merged.N)\n",
    "\n",
    "# Plot initial classified image\n",
    "lc_map.plot.imshow(ax=axes[0], \n",
    "               cmap=cmap,\n",
    "               norm=norm,\n",
    "               add_labels=True, \n",
    "               add_colorbar=False,\n",
    "               interpolation='none')\n",
    "\n",
    "# Plot post-processed classified image\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "               cmap=cmap_merged,\n",
    "               norm=norm_merged,\n",
    "               add_labels=True, \n",
    "               add_colorbar=False,\n",
    "               interpolation='none')\n",
    "\n",
    "# Remove axis on middle and right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legends\n",
    "axes[0].legend(patches_list, list(dict_map.keys()),\n",
    "    loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "axes[1].legend(patches_list_merged, list(dict_map_merged.keys()),\n",
    "    loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image')\n",
    "axes[1].set_title('Classified Image - Postprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690f01c-0333-4da0-8c22-c66cbf347be8",
   "metadata": {},
   "source": [
    "## Save as geotiff\n",
    "We can now export our post-processed result to sandbox disk as Cloud-Optimised GeoTIFF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2077ff-46cb-47c0-8889-3739cf0a3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cog(lc_map_postproc, 'Results/Land_cover_prediction_postprocessed.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee70faf-3cee-4cd0-ae29-200adf453c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
