{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13adbce-103d-40c4-88bd-bb94d3d848f1",
   "metadata": {},
   "source": [
    "# Post-process: Smoothing and Reclassify Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fb223-9745-4711-9a51-a1384dbcc63e",
   "metadata": {},
   "source": [
    "## Background\n",
    "In real case studies machine learning may not predict desired classification maps due to factors including limited training data and limited performance of the model for prediction. Therefore, post-processing is widely applied to the predicted classification results, based on assumptions or existing knowlegde of the ground truth. Commonly applied post-processing includes manual editing, filtering, reclassification and class merging, etc.  \n",
    "\n",
    "## Description\n",
    "In this notebook we will apply post-processing to the land cover maps we produced through the previous notebook. We'll also conduct a median filtering to reduce the 'salt and pepper' effect resulted from pixel-based classification. We will then use external layers that contain reliable information on certain classes and/or have higher-spatial resolution to reclassify classes that may be misclassified by the random forest classifier. These external layers have been prepared and uploaded into 'Data/' folder. This notebook will demonstrate how to do implement these post-processings and visualise the comparison before and after the post-processing. The steps are as follows:\n",
    "1. Load the external layers and land cover maps produced at the testing locations\n",
    "2. Majority filtering of the maps to reduce salt-and-pepper effects\n",
    "3. Apply customised reclassification rules using prepared external layers\n",
    "4. Plot the land cover maps before and after post-processing steps applied\n",
    "5. Save the results to disk as COGs\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f4e28-0a6a-4d30-973d-e2f1b20acf2a",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4986f5-2e04-4e64-8ff0-25119e9468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import datacube\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.plotting import rgb\n",
    "from skimage.morphology import binary_dilation,disk\n",
    "from skimage.filters.rank import modal\n",
    "from skimage.segmentation import expand_labels\n",
    "from odc.algo import xr_reproject\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap,BoundaryNorm\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74765-a79f-4bb2-baa5-240c6cacc41e",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "* `prediction_maps_path`: A list of file paths and names of the classification maps produced in the previous notebook.\n",
    "* `rgb_images_path`: A list of file paths and names of the true colour images at the prediction locations exported in the previous notebook.\n",
    "* `dict_map`: A dictionary map of class names corresponding to pixel values.\n",
    "* `output_crs`: Coordinate reference system for output raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269eb27c-1692-4461-830b-185ffaa8008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps_path=['Results/Land_cover_prediction_Kicukiro_location_'+str(i)+'.tif' for i in range(3)] # list of prediction map files\n",
    "rgb_images_path=['Results/S2_RGB_image_Kicukiro_location_'+str(i)+'.tif' for i in range(3)] # list of rgb images at the prediction locations\n",
    "dict_map={'Forest':1,'Grassland':5,'Shrubland':7,'Perennial Cropland':9,'Annual Cropland':10,\n",
    "          'Wetland':11,'Water Body':12,'Urban Settlement':13,'Bare Land':14} # a dictionary of pixel value for each class\n",
    "output_crs='epsg:32735' # WGS84/UTM Zone 35S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9884a-c98d-4d0a-8dca-d1cadb986c36",
   "metadata": {},
   "source": [
    "## External Layers\n",
    "A few external layers for Rwanda were sourced and prepared in the 'Data/' folder, which are helpful to add information on specific classes. The external layers include:  \n",
    "* `river_network_shp`: OSM river network shapefile. The OSM layers were sourced from the [Humanitarian OpenStreetMap Team (HOT)](https://data.humdata.org/organization/hot) website.\n",
    "* `road_network_shp`: OSM road network shapefile.\n",
    "* `google_building_raster`: A rasterised layer of [Google Open Building](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_Research_open-buildings_v2_polygons) polygons, which consist of outlines of buildings derived from high-resolution 50 cm satellite imagery. As there are many polygons in the original vector layer, we rasterised the layer to 10 m resolution to reduce disk storage and memory required for processing.  \n",
    "* `wsf2019_raster`: 2019 [World Settlement Footprint (WSF)](https://gee-community-catalog.org/projects/wsf/) layer, a 10m resolution binary mask outlining the extent of human settlements globally derived by means of 2019 multitemporal Sentinel-1 and Sentinel-2 imagery.  \n",
    "* `hand_raster`: Hydrologically adjusted elevations, i.e. Height Above the Nearest Drainage (hand) derived from the [MERIT Hydro dataset](https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1#description).\n",
    "* `parks_json`: Boundaries of [national parks or reserve](https://geodata.rw/server/rest/services/basemap/National_Parks/FeatureServer/0) declared or registered by the government in geojson format.\n",
    "* `wetlands_json`: Boundaries of [declaired swamps borders](https://geodata.rw/server/rest/services/basemap/Wetland/FeatureServer/0) in geojson format.\n",
    "\n",
    "> Note: In this notebook we have made the data prepared for you to run through the demonstration. If you would like to apply it to your own project, you may need to spend some time sourcing the datasets and do some pre-processing if needed, e.g. clipping to your study area, filtering, rasterisation or vectorisation. Alternatively you can revise this notebook depending on the file format of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12234399-7fda-4885-bce2-478634840400",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network_shp='Data/hotosm_rwa_waterways_lines_filtered.shp' # OSM river network data\n",
    "road_network_shp='Data/hotosm_rwa_roads_lines_filtered.shp' # OSM road network data\n",
    "google_building_raster='Data/GoogleBuildingLayer_Rwanda_reprojected_rasterised.tif' # rasterised google bulding layer\n",
    "wsf2019_raster='Data/WSF2019_v1_Rwanda_clipped.tif' # 2019 World Settlement Footprint layer\n",
    "hand_raster='Data/hand_Rwanda.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "parks_json='Data/National Parks.geojson' # National parks layer\n",
    "wetlands_json='Data/Wetland.geojson' # wetlands layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2b93c-e69f-46b1-9df4-715dc11f0b04",
   "metadata": {},
   "source": [
    "## Load land cover maps and external layers\n",
    "First let's load the land cover maps and true colour images generated from the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c855d-7100-4d48-8a8b-5219ddcf0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import land cover map of 2021 and reproject\n",
    "prediction_maps=[]\n",
    "rgb_images=[]\n",
    "for i in range(0, len(prediction_maps_path)):\n",
    "    lc_map=rioxarray.open_rasterio(prediction_maps_path[i]).astype(np.uint8).squeeze()\n",
    "    prediction_maps.append(lc_map)\n",
    "    \n",
    "    rgb_image=rioxarray.open_rasterio(rgb_images_path[i])\n",
    "    rgb_images.append(rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64fc6c-856d-4185-926d-76d44872243c",
   "metadata": {},
   "source": [
    "We then load other layers. The OSM road network layer contains multi-lines with various surface attributes. We'll select some major road types and buffer them by 10 metres. Similarly we load and select major waterways from the OSM river network layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616870ab-3aad-439d-bbae-9833ab9e3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_network=gpd.read_file(road_network_shp).to_crs(output_crs) \n",
    "road_network=road_network.loc[road_network['surface'].isin(['asphalt', 'paved', 'compacted', 'cobblestone', \n",
    "                                                             'concrete', 'metal', 'paving_stones', \n",
    "                                                             'paving_stones:30'])] # select road network by attributes\n",
    "road_network.geometry=road_network.geometry.buffer(10) # buffer the road network by 10m\n",
    "\n",
    "river_network=gpd.read_file(river_network_shp).to_crs(output_crs) # import OSM river network data and reproject\n",
    "river_network=river_network.loc[river_network['waterway'].isin(['canal','river'])] # select river network by attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8469a6-6e9b-44f1-a975-622f258eb170",
   "metadata": {},
   "source": [
    "We now load the Google buildings, WSF 2019 and 'hand' rasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c28d0d-b5a2-4a83-9567-6e2e17a6b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings=xr.open_dataset(google_building_raster,engine=\"rasterio\").squeeze() # import google bulding layer\n",
    "hand=xr.open_dataset(hand_raster,engine=\"rasterio\").squeeze() # import hand layer\n",
    "wsf2019=xr.open_dataset(wsf2019_raster,engine=\"rasterio\").squeeze().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0f0ae",
   "metadata": {},
   "source": [
    "Finally let's load the national parks and wetlands layers, and select the national parks with no agricultural activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d98c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks=gpd.read_file(parks_json).to_crs(output_crs)\n",
    "parks=parks.loc[parks['type'].isin(['National Park','Volcanoes National Park'])]\n",
    "wetlands=gpd.read_file(wetlands_json).to_crs(output_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6beb26-1701-4135-802f-53d65cd7cab8",
   "metadata": {},
   "source": [
    "## Morphological filtering\n",
    "Now we start the post-processing by applying a majority filtering, a commonly applied step to reduce salt-and-pepper noise typical in pixel-based classification. To demonstrate each post-processing step we will process the first prediction map, then put the steps together in an iterative loop to process all prediction. The majority filtering is applied within each local window with a given footprint. Here we use a disk with radius of one pixel. It is advised that you adjust the footprint depending on your prediction results and desired effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e80c9-6a86-41f4-8548-d8fa505f0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lc_map=prediction_maps[i]\n",
    "# convert to numpy array\n",
    "np_lc_map=lc_map.squeeze().to_numpy()\n",
    "# mode filtering for a smoother classification map\n",
    "np_lc_map_postproc=modal(np_lc_map,footprint=disk(1),mask=np_lc_map!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2edbe-931e-4b9b-b6e0-b70831db4c59",
   "metadata": {},
   "source": [
    "We can plot and compare the maps before and after filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db33bbc-ccc6-4e4a-b567-fb3338e18c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct dataArray\n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "# display colour for each class value\n",
    "colours = {1:'green', 5:'gold', 7:'chocolate',9:'violet',10:'pink',11:'cyan',12:'blue',13:'gray',14:'seashell'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# Plot classified image before filtering\n",
    "prediction_values=np.unique(lc_map)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "lc_map.plot.imshow(ax=axes[0], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "\n",
    "# Plot classified image after filtering\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "# Remove axis on right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legend\n",
    "patches_list=[Patch(facecolor=colour) for colour in colours.values()]\n",
    "axes[1].legend(patches_list, list(dict_map.keys()),loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Majority Filtering')\n",
    "axes[1].set_title('Classified Image After Majority Filtering')\n",
    "\n",
    "# make a copy of intermediate result\n",
    "lc_map_filtered=lc_map_postproc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce998fb4-8426-46a1-9684-e8c274884eb5",
   "metadata": {},
   "source": [
    "## Apply rules using external layers\n",
    "Now let's reclassify some classes using the external layers. We will apply the following processing rules:  \n",
    "* Merging Perennial Cropland and Annual Cropland as Cropland class;\n",
    "* Assign Cropland pixels within national parks as Shrubland;\n",
    "* Assign Urban Settlement pixels within national parks as surrounding classes;\n",
    "* Assign Wetland pixels outside wetlands polygons as Shrubland;\n",
    "* Assign Bare Land or Urban Settlement pixels within DE Africa 2019 cropland mask as Cropland;\n",
    "* Assign Cropland pixels outside DE Africa 2019 cropland mask as Shrubland;\n",
    "* Assign Water Body pixels as surrounding class if they donâ€™t occur at bottom of watersheds and fall outside OSM river networks;\n",
    "* Assign pixels overlapping OSM river network as Water Body;\n",
    "* Assign pixels overlapping google building polygons, WSF 2019 or OSM road network (10 m buffered) layers as Urban Settlement.\n",
    "\n",
    "> Note: The reclassification rules applied in this notebook are very customised and may not apply to other countries or datasets. What rules to apply depend on various factors including your preliminary knowledge on the study area, the reliability of the external layers and your classes of most interest/priority. Therefore, you may need to revise or refine the processing rules applied here to fit your own application needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75ff37-955c-4304-9b2f-62d32d0aa0e2",
   "metadata": {},
   "source": [
    "Before applying reclassification using other layers, one thing to note for raster-based calculation is to make sure all rasters are in the same spatial reference and align with each other. Here we extract the `geobox` of the land cover map, which defines the location and resolution of the grid data including spatial reference. We will use it to reproject other layers to be aligned with the land cover map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_geobox=lc_map.geobox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef398d8f",
   "metadata": {},
   "source": [
    "First, we merge Perennial Cropland and Annual Cropland as a single class Cropland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f13e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lc_map_postproc[np_lc_map_postproc==dict_map['Perennial Cropland']]=dict_map['Annual Cropland']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5663ec",
   "metadata": {},
   "source": [
    "As there is unlikely agricultural activities within national parks, the Cropland pixels within national parks are likely to be misclassified. After checking on the results, we believe they are most likely to be Shrubland, so we assign these misclassified pixels as Shrubland. Similarly we assign Urban Settlement pixels within national parks as surrounding classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterise national parks layer\n",
    "parks_mask=xr_rasterize(gdf=parks,da=lc_map.squeeze(),transform=ds_geobox.transform,crs=output_crs)\n",
    "np_parks_mask=parks_mask.squeeze().to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[(np_lc_map_postproc==dict_map['Annual Cropland'])&(np_parks_mask==1)]=dict_map['Shrubland']\n",
    "\n",
    "# make a copy of land cover array\n",
    "lc_copy=np_lc_map_postproc.copy()\n",
    "# assign the regions as background (0)\n",
    "lc_copy[(np_lc_map_postproc==dict_map['Urban Settlement'])&(np_parks_mask==1)]=0\n",
    "# expand surrounding classes of background pixels\n",
    "lc_copy_closed=expand_labels(lc_copy,distance=10000)\n",
    "# identify filled/changed areas\n",
    "mask=(lc_copy!=lc_copy_closed)\n",
    "# copy the filled/changed pixels\n",
    "np_lc_map_postproc[mask]=lc_copy_closed[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecdc7c7",
   "metadata": {},
   "source": [
    "We believe that the wetland layer includes all wetlands, so we assign Wetland pixels outside the wetland polygons as Shrubland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wetlands_mask=xr_rasterize(gdf=wetlands,da=lc_map.squeeze(),transform=ds_geobox.transform,crs=output_crs)\n",
    "np_wetlands_mask=wetlands_mask.squeeze().to_numpy()\n",
    "np_lc_map_postproc[(np_lc_map_postproc==dict_map['Wetland'])&(np_wetlands_mask!=1)]=dict_map['Shrubland']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad1efa",
   "metadata": {},
   "source": [
    "We observed that there are more Bare Land and Urban Settlement pixels than expected, and a lot of them appear to be croplands, so we use the [DE Africa 2019 cropland mask](https://docs.digitalearthafrica.org/en/latest/data_specs/Cropland_extent_specs.html) and assign the misclassified pixels as Cropland. Besides, we believe that the crop mask is comprehensive, so cropland pixels outside the mask are likely to have been misclassified from other classes. In this example they are mostly likely to be Shrubland, so we assign these cropland pixels as Shrubland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DE Africa crop mask 2019\n",
    "dc = datacube.Datacube(app='cropland_extent')\n",
    "x_min,y_min,x_max,y_max=ds_geobox.extent.boundingbox\n",
    "query = {\n",
    "    'time': ('2019'),\n",
    "    'x': (x_min,x_max),\n",
    "    'y': (y_min,y_max),\n",
    "    'resolution':(-10, 10),\n",
    "    'crs':output_crs,\n",
    "    'output_crs': output_crs,\n",
    "}\n",
    "# now load the crop-mask using the query\n",
    "cm = dc.load(product='crop_mask',**query).squeeze()\n",
    "np_crop_mask=cm['mask'].to_numpy()\n",
    "# apply the rules\n",
    "np_lc_map_postproc[((np_lc_map_postproc==dict_map['Bare Land'])|(np_lc_map_postproc==dict_map['Urban Settlement']))\n",
    "&(np_crop_mask==1)]=dict_map['Annual Cropland']\n",
    "np_lc_map_postproc[(np_lc_map_postproc==dict_map['Annual Cropland'])&(np_crop_mask!=1)]=dict_map['Shrubland']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1a8d5",
   "metadata": {},
   "source": [
    "To include more Water Body pixels that are misclassified to other classes, we use the OSM river network layer and assign pixels overlapping the layer as Water Body. Meanwhile, to make sure water only occurs at bottom of watersheds, i.e. height above nearest drainage below 45m, or falls within OSM river networks, we assign Water Body pixels outside these areas as surrounding classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47515c1-b690-4499-a2a4-3b8eb127b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject hand layer\n",
    "hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_hand=hand.to_array().squeeze().to_numpy()\n",
    "# rasterise river network layer\n",
    "river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                  da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=output_crs)\n",
    "# convert to numpy array\n",
    "np_river_network_mask=river_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[np_river_network_mask==1]=dict_map['Water Body']\n",
    "\n",
    "# make a copy of land cover array\n",
    "lc_copy=np_lc_map_postproc.copy()\n",
    "# assign the regions as background (0)\n",
    "lc_copy[(np_lc_map_postproc==dict_map['Water Body'])&(np_hand>45)&(np_river_network_mask!=1)]=0\n",
    "# expand surrounding classes of background pixels\n",
    "lc_copy_closed=expand_labels(lc_copy,distance=10000)\n",
    "# identify filled/changed areas\n",
    "mask=(lc_copy!=lc_copy_closed)\n",
    "# copy the filled/changed pixels\n",
    "np_lc_map_postproc[mask]=lc_copy_closed[mask] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277ce2a-363b-482c-b254-93da232b77eb",
   "metadata": {},
   "source": [
    "Finally, we assign pixels overlapping google building polygons, WSF 2019 mask or OSM road network (10m buffered) as Urban Settlement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e72cd0-ee13-4332-b6b7-430873016db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject google buildings raster\n",
    "google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "# reproject WSF 2019 layer\n",
    "wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "# convert to numpy array\n",
    "np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "# rasterise road network layer\n",
    "road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                              da=lc_map.squeeze(),\n",
    "                              transform=ds_geobox.transform,\n",
    "                              crs=output_crs)\n",
    "# convert to numpy\n",
    "np_road_network_mask=road_network_mask.to_numpy()\n",
    "# apply rule\n",
    "np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==255)|(np_road_network_mask==1)]=dict_map['Urban Settlement']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3918b4-ad54-47e4-a7e4-ff11bc23c6ae",
   "metadata": {},
   "source": [
    "We can plot the maps to see a comparison before and after applying the rules using the external layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e248c-d5dc-4d3b-bc27-0362e452edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# set color legends and color maps parameters\n",
    "prediction_values=np.unique(lc_map_filtered)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "\n",
    "dict_map_merged={'Forest':1,'Grassland':5,'Shrubland':7,'Cropland':10,\n",
    "          'Wetland':11,'Water Body':12,'Urban Settlement':13,'Bare Land':14}\n",
    "colours_merged={1:'green', 5:'gold', 7:'chocolate',10:'pink',11:'cyan',12:'blue',13:'gray',14:'seashell'}\n",
    "patches_list_merged=[Patch(facecolor=colour) for colour in colours_merged.values()]\n",
    "prediction_values_merged=np.unique(lc_map_postproc)\n",
    "cmap_merged=ListedColormap([colours_merged[k] for k in prediction_values_merged])\n",
    "norm_merged = BoundaryNorm(list(prediction_values_merged)+[np.max(prediction_values_merged)+1], cmap_merged.N)\n",
    "\n",
    "# Plot classified image before applying rules\n",
    "lc_map_filtered.plot.imshow(ax=axes[0], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "\n",
    "# Plot classified image after applying rules\n",
    "# reconstruct dataArray\n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap_merged,\n",
    "                   norm=norm_merged,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "# Remove axis on right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legends\n",
    "axes[0].legend(patches_list, list(dict_map.keys()),\n",
    "    loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "axes[1].legend(patches_list_merged, list(dict_map_merged.keys()),\n",
    "    loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Applying Rules')\n",
    "axes[1].set_title('Classified Image After Applying Rules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f113f9-9a6b-414e-8973-8682f5309103",
   "metadata": {},
   "source": [
    "## Processing and visualisation for all testing locations\n",
    "Now let's process all three locations by simply copying and putting together all the post-processing steps, and iterating through all three locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps_postproc=[] # post-processed results\n",
    "# loop through all testing locations\n",
    "for i in range(0,len(prediction_maps)):\n",
    "    lc_map=prediction_maps[i]\n",
    "    # convert to numpy array\n",
    "    np_lc_map=lc_map.squeeze().to_numpy()\n",
    "\n",
    "    # --------------------mode filtering for a smoother classification map----------------------#\n",
    "    np_lc_map_postproc=modal(np_lc_map,footprint=disk(1),mask=np_lc_map!=0)\n",
    "\n",
    "    # get geobox\n",
    "    ds_geobox=lc_map.geobox\n",
    "\n",
    "    # merging two cropland classes\n",
    "    np_lc_map_postproc[np_lc_map_postproc==dict_map['Perennial Cropland']]=dict_map['Annual Cropland']\n",
    "\n",
    "    #--------------------reassign Cropland within national parks as Shrubland------------------------#\n",
    "    # rasterise national parks layer\n",
    "    parks_mask=xr_rasterize(gdf=parks,da=lc_map.squeeze(),transform=ds_geobox.transform,crs=output_crs)\n",
    "    np_parks_mask=parks_mask.squeeze().to_numpy()\n",
    "    # apply the rule\n",
    "    np_lc_map_postproc[(np_lc_map_postproc==dict_map['Annual Cropland'])&(np_parks_mask==1)]=dict_map['Shrubland']\n",
    "\n",
    "    #--------------------reassign Urban Settlement within national parks as surrounding classes------------------------#\n",
    "    # make a copy of land cover array\n",
    "    lc_copy=np_lc_map_postproc.copy()\n",
    "    # assign the regions as background (0)\n",
    "    lc_copy[(np_lc_map_postproc==dict_map['Urban Settlement'])&(np_parks_mask==1)]=0\n",
    "    # expand surrounding classes of background pixels\n",
    "    lc_copy_closed=expand_labels(lc_copy,distance=10000)\n",
    "    # identify filled/changed areas\n",
    "    mask=(lc_copy!=lc_copy_closed)\n",
    "    # copy the filled/changed pixels\n",
    "    np_lc_map_postproc[mask]=lc_copy_closed[mask]\n",
    "\n",
    "    #--------------------reassign Wetland outside wetland polygons as Shrubland------------------------#\n",
    "    wetlands_mask=xr_rasterize(gdf=wetlands,da=lc_map.squeeze(),transform=ds_geobox.transform,crs=output_crs)\n",
    "    np_wetlands_mask=wetlands_mask.squeeze().to_numpy()\n",
    "    np_lc_map_postproc[(np_lc_map_postproc==dict_map['Wetland'])&(np_wetlands_mask!=1)]=dict_map['Shrubland']\n",
    "\n",
    "    #------reassign Bare Land and Urban Settlement within DE Africa crop mask as Cropland; Cropland outside the mask as Shrubland------#\n",
    "    # load DE Africa crop mask 2019\n",
    "    dc = datacube.Datacube(app='cropland_extent')\n",
    "    # extract bounding box\n",
    "    x_min,y_min,x_max,y_max=ds_geobox.extent.boundingbox\n",
    "    query = {\n",
    "        'time': ('2019'),\n",
    "        'x': (x_min,x_max),\n",
    "        'y': (y_min,y_max),\n",
    "        'resolution':(-10, 10),\n",
    "        'crs':output_crs,\n",
    "        'output_crs': output_crs,\n",
    "    }\n",
    "    # now load the crop-mask using the query\n",
    "    cm = dc.load(product='crop_mask',**query).squeeze()\n",
    "    np_crop_mask=cm['mask'].to_numpy()\n",
    "    # apply the rules\n",
    "    np_lc_map_postproc[((np_lc_map_postproc==dict_map['Bare Land'])|(np_lc_map_postproc==dict_map['Urban Settlement']))\n",
    "    &(np_crop_mask==1)]=dict_map['Annual Cropland']\n",
    "    np_lc_map_postproc[(np_lc_map_postproc==dict_map['Annual Cropland'])&(np_crop_mask!=1)]=dict_map['Shrubland']\n",
    "\n",
    "    #--------------------assign pixels within OSM river network as Water Body------------------------#\n",
    "    # reproject hand layer\n",
    "    hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "    # convert to numpy array\n",
    "    np_hand=hand.to_array().squeeze().to_numpy()\n",
    "    # rasterise river network layer\n",
    "    river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                    da=lc_map.squeeze(),\n",
    "                                    transform=ds_geobox.transform,\n",
    "                                    crs=output_crs)\n",
    "    # convert to numpy array\n",
    "    np_river_network_mask=river_network_mask.to_numpy()\n",
    "    # apply the rule\n",
    "    np_lc_map_postproc[np_river_network_mask==1]=dict_map['Water Body']\n",
    "\n",
    "    #--------------------make sure water body only present at bottom of watershed or within OSM river network-----------#\n",
    "    # make a copy of land cover array\n",
    "    lc_copy=np_lc_map_postproc.copy()\n",
    "    # assign the regions as background (0)\n",
    "    lc_copy[(np_lc_map_postproc==dict_map['Water Body'])&(np_hand>45)&(np_river_network_mask!=1)]=0\n",
    "    # expand surrounding classes of background pixels\n",
    "    lc_copy_closed=expand_labels(lc_copy,distance=10000)\n",
    "    # identify filled/changed areas\n",
    "    mask=(lc_copy!=lc_copy_closed)\n",
    "    # copy the filled/changed pixels\n",
    "    np_lc_map_postproc[mask]=lc_copy_closed[mask]\n",
    "\n",
    "    #--------------------assign pixels overlapping google building, WSF 2019 and OSM road network as Urban Settlement---------#\n",
    "    # reproject google buildings raster\n",
    "    google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "    # convert to numpy array\n",
    "    np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "    # reproject WSF 2019 layer\n",
    "    wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "    # convert to numpy array\n",
    "    np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "    # rasterise road network layer\n",
    "    road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                                da=lc_map.squeeze(),\n",
    "                                transform=ds_geobox.transform,\n",
    "                                crs=output_crs)\n",
    "    # convert to numpy\n",
    "    np_road_network_mask=road_network_mask.to_numpy()\n",
    "    # apply rule\n",
    "    np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==255)|(np_road_network_mask==1)]=dict_map['Urban Settlement']\n",
    "\n",
    "    #------------------------------reconstruct processed result as Xarray---------------------------------#\n",
    "    # \n",
    "    lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "    # set spatial reference\n",
    "    lc_map_postproc.rio.write_crs(output_crs, inplace=True)\n",
    "    # append to list\n",
    "    prediction_maps_postproc.append(lc_map_postproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9e53c-0b31-4fdc-b613-23da0c566a78",
   "metadata": {},
   "source": [
    "We can compare all final post-processed results with initial predictions without post-processing, along with the satellite images for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab9e08-ec61-43e2-a05e-33a8865be61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(prediction_maps)):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    # Plot true colour image\n",
    "    rgb(rgb_images[i].to_dataset(dim='band'),bands=[1,2,3],\n",
    "        ax=axes[0], percentile_stretch=(0.01, 0.99))\n",
    "    \n",
    "    # set color legends and color maps parameters\n",
    "    prediction_values=np.unique(prediction_maps[i])\n",
    "    cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "    norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "\n",
    "    prediction_values_merged=np.unique(prediction_maps_postproc[i])\n",
    "    cmap_merged=ListedColormap([colours_merged[k] for k in prediction_values_merged])\n",
    "    norm_merged = BoundaryNorm(list(prediction_values_merged)+[np.max(prediction_values_merged)+1], cmap_merged.N)\n",
    "    \n",
    "    # Plot initial classified image\n",
    "    prediction_maps[i].plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "    \n",
    "    # Plot post-processed classified image\n",
    "    prediction_maps_postproc[i].plot.imshow(ax=axes[2], \n",
    "                   cmap=cmap_merged,\n",
    "                   norm=norm_merged,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "                   \n",
    "    # Remove axis on middle and right plot\n",
    "    axes[1].get_yaxis().set_visible(False)\n",
    "    axes[2].get_yaxis().set_visible(False)\n",
    "    # add colour legends\n",
    "    axes[1].legend(patches_list, list(dict_map.keys()),\n",
    "        loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "    axes[2].legend(patches_list_merged, list(dict_map_merged.keys()),\n",
    "        loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "    # Add plot titles\n",
    "    axes[0].set_title('True Colour Geomedian')\n",
    "    axes[1].set_title('Classified Image')\n",
    "    axes[2].set_title('Classified Image - Postprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690f01c-0333-4da0-8c22-c66cbf347be8",
   "metadata": {},
   "source": [
    "## Save as geotiff\n",
    "We can now export our post-processed results to sandbox disk as Cloud-Optimised GeoTIFFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2077ff-46cb-47c0-8889-3739cf0a3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(prediction_maps_postproc)):\n",
    "    write_cog(prediction_maps_postproc[i], 'Results/Land_cover_prediction_postprocessed_Kicukiro_location_'+str(i)+'.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee70faf-3cee-4cd0-ae29-200adf453c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
